#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Jul  2 09:59:06 2020

Step 6 to reproduce results of NPJ paper:
"The role of the Pacific Decadal Oscillation and
ocean-atmosphere interactions in driving US temperature variability"

It loads data that is generated by step 1.
This scripts generates the results presented in Table 2.

@author: semvijverberg
"""
#%% Load packages and define paths

from __future__ import division
import os, inspect, sys
import matplotlib as mpl
if sys.platform == 'linux':
    mpl.use('Agg')
else:
    # Optionally set font to Computer Modern to avoid common missing font errors
    mpl.rc('font', family='serif', serif='cm10')

    mpl.rc('text', usetex=True)
    mpl.rcParams['text.latex.preamble'] = r'\boldmath'
import numpy as np
import cartopy.crs as ccrs
import pandas as pd
import argparse

user_dir = os.path.expanduser('~')
curr_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe()))) # script directory
main_dir = '/'.join(curr_dir.split('/')[:-2])
RGCPD_func = os.path.join(main_dir, 'RGCPD')
assert main_dir.split('/')[-1] == 'RGCPD', 'main dir is not RGCPD dir'
cluster_func = os.path.join(main_dir, 'clustering/')
fc_dir = os.path.join(main_dir, 'forecasting')
data_dir = os.path.join(main_dir,'publications/Vijverberg_Coumou_2022_NPJ/data')
if cluster_func not in sys.path:
    sys.path.append(main_dir)
    sys.path.append(RGCPD_func)
    sys.path.append(cluster_func)
    sys.path.append(fc_dir)

path_raw = user_dir + '/surfdrive/ERA5/input_raw'


from RGCPD import RGCPD
from RGCPD import BivariateMI
from RGCPD import class_BivariateMI
from RGCPD.forecasting import func_models as fc_utils
from RGCPD import functions_pp;
from RGCPD import core_pp
#%% Global parameter


targets = ['easterntemp']#, 'westerntemp']

periods = ['JA_center']#, 'JA_shiftright', 'JA_shiftleft', 'JJA_center']
seeds = np.array([1,2,3,4,5])
combinations = np.array(np.meshgrid(targets, periods, seeds)).T.reshape(-1,3)

i_default = 0 #8

def parseArguments():
    # Create argument parser
    parser = argparse.ArgumentParser()

    # Optional arguments
    parser.add_argument("-i", "--intexper", help="intexper", type=int,
                        default=i_default)
    # Parse arguments
    args = parser.parse_args()
    return args


if __name__ == '__main__':
    args = parseArguments()
    out = combinations[args.intexper]
    target = out[0]
    period = out[1]
    seed = int(out[2])
    # remove_PDO = bool(int(out[3]))
    if target[-4:]=='temp':
        tfreq = 2
    else:
        tfreq = 2
    print(f'arg {args.intexper} f{out}')


calc_ts = 'region mean'

if target[-4:] == 'temp':
    #original
    cluster_label = 2
    TVpath = os.path.join(data_dir, 'tfreq15_nc7_dendo_57db0USCA.nc')
    alpha_corr = .05

    name_ds='ts'
    if target == 'westerntemp':
        cluster_label = 1
    elif target == 'easterntemp':
        cluster_label = 4 # cluster_label = 2
elif target[-2:] == 'RW':
    cluster_label = 'z500'
    name_ds = f'0..0..{cluster_label}_sp'
    alpha_corr = .05
    if target == 'easternRW':
        TVpath = os.path.join(data_dir, 'eastRW_summer_center_s1.h5')
    elif target == 'westernRW':
        TVpath = os.path.join(data_dir, 'westRW_summer_center_s1.h5')

# select target period
if period == 'JA_center':
    start_end_TVdate = ('07-01', '08-31')
elif period == 'JA_shiftleft':
    start_end_TVdate = ('06-25', '08-24')
elif period == 'JA_shiftright':
    start_end_TVdate = ('07-08', '09-06')
elif period == 'JJA_center':
    start_end_TVdate = ('07-01', '08-31')

start_end_date = ('01-01', '12-31')
precur_aggr = tfreq
method     = 'ranstrat_10' ;
n_boot = 0
min_detect_gc = 0.9
append_main = ''



#%% run RGDR
# paths to input data
list_of_name_path = [(cluster_label, TVpath),
                     ('sst', os.path.join(path_raw, 'sst_1979-2020_1_12_monthly_1.0deg.nc'))]

# parameters for RGDR analysis (here called BivariateMI).
lags=np.array([1])
tfreq = 2
min_area_in_degrees2=3

list_for_MI   = [BivariateMI(name='sst', func=class_BivariateMI.corr_map,
                            alpha=alpha_corr, FDR_control=True,
                            kwrgs_func={}, group_split='together',
                            distance_eps=500, min_area_in_degrees2=min_area_in_degrees2,
                            calc_ts=calc_ts, selbox=(130,260,-10,60),
                            lags=lags)]

path_out_main = os.path.join(main_dir, f'publications/Vijverberg_Coumou_2022_NPJ/output/{target}{append_main}/')

rg = RGCPD(list_of_name_path=list_of_name_path,
           list_for_MI=list_for_MI,
           start_end_TVdate=start_end_TVdate,
           start_end_date=start_end_date,
           start_end_year=None,
           tfreq=tfreq,
           path_outmain=path_out_main)
if rg.list_for_MI[0]._name == 'sst_corr_map':
    title = r'$corr(SST_{t-1}$' + f'$, T^{target[0].capitalize()}_t)$'
else:
    title = r'$parcorr(SST_{t-lag}, mx2t_t\ |\ SST_{t-1},mx2t_{t-1})$'

kwrgs_plotcorr = {'row_dim':'split', 'col_dim':'lag','aspect':2, 'hspace':-.47,
              'wspace':-.15, 'size':3, 'cbar_vert':-.1,
              'units':'Corr. Coeff. [-]', 'zoomregion':(130,260,-10,60),
              'clim':(-.60,.60), 'map_proj':ccrs.PlateCarree(central_longitude=220),
              'y_ticks':np.arange(-10,61,20), 'x_ticks':np.arange(140, 280, 25),
              'title':title,
              'title_fontdict':{'fontsize':20, 'fontweight':'bold', 'y':1.07}}
sst = rg.list_for_MI[0]

append_str='{}d_{}'.format(tfreq, calc_ts.split(' ')[0])
kwrgs_MI = [str(i)+str(k) for i,k in sst.kwrgs_func.items()]
if len(kwrgs_MI) != 0:
    append_str += '_' + '_'.join(kwrgs_MI)
#%%

rg.pp_TV(name_ds=name_ds, detrend=False, anomaly=True, kwrgs_core_pp_time={'dailytomonths':True})

subfoldername = '_'.join(['vs_lags',rg.hash, period,
                      str(precur_aggr), str(alpha_corr).split('.')[1], method,
                      str(seed)])

rg.pp_precursors()
rg.traintest(method=method, seed=seed, subfoldername=subfoldername)
rg.calc_corr_maps()
rg.cluster_list_MI()
kwrgs_plotlabels = kwrgs_plotcorr.copy()
kwrgs_plotlabels.pop('title') ; kwrgs_plotlabels.pop('units')
rg.quick_view_labels(save=True, append_str=f'{tfreq}d',
                     min_detect_gc=min_detect_gc,
                     kwrgs_plot=kwrgs_plotlabels)
# plotting corr_map
rg.plot_maps_corr(var='sst', save=True,
                  kwrgs_plot=kwrgs_plotcorr,
                  min_detect_gc=min_detect_gc,
                  append_str=f'{tfreq}d')


#%% Get PDO and apply low-pass filter
from RGCPD import climate_indices
from sklearn import preprocessing

# filepath_df_PDOs = os.path.join(data_dir, 'df_PDOs_daily.h5')
filepath_df_PDOs = os.path.join(data_dir, 'df_PDOs.h5')



try:
    df_PDOs = functions_pp.load_hdf5(filepath_df_PDOs)['df_data']
except:

    SST_pp_filepath = user_dir + '/surfdrive/ERA5/input_raw/preprocessed/sst_1979-2020_1jan_31dec_daily_1.0deg.nc'

    if 'df_PDOsplit' not in globals():
        # get PDO timeseries, using the same training sample as for RGDR
        df_PDO, PDO_patterns = climate_indices.PDO(SST_pp_filepath,
                                                   rg.df_splits)

        # line below only used when comparing skill wrt in-sample PDO (Not done in paper)
        # df_PDO = pd.concat([df_PDO.loc[0][['PDO']]]*rg.n_spl, keys=range(rg.n_spl))

    # functions_pp.store_hdf_df({'df_data':df_PDOs},
    #                           file_path=filepath_df_PDOs)

#%% forecasting functions
def get_lagged_ts(df_data, lag, keys=None):
    if keys is None:
        keys = df_data.columns[df_data.dtypes != bool]
    df_lagmask = []
    for s in df_data.index.levels[0]:
        lagmask = fc_utils.apply_shift_lag(df_data.loc[s][['TrainIsTrue', 'RV_mask']], lag)
        df_lagmask.append(lagmask)
    df_lagmask = pd.concat(df_lagmask, keys=df_data.index.levels[0])
    # persPDO = functions_pp.get_df_test(rgPDO.df_data[keys_ext+['TrainIsTrue']])[keys_ext]
    df_lag = df_data[df_lagmask['x_fit']]
    df_lag.index = df_data[df_lagmask['y_fit']].index
    return df_lag[keys].rename({k:k+f'_{lag}' for k in keys}, axis=1), df_lagmask

def merge_lagged_wrapper(df_data, lags, keys):
    df_data_l = []
    for lag in lags:
        df_data_lag, df_lagmask1 = get_lagged_ts(df_data.copy() , lag, keys)
        df_data_l.append(df_data_lag)

    return pd.concat(df_data_l, axis=1)

def prediction_wrapper(df_data, lags, target_ts=None, keys: list=None, match_lag: bool=False,
                       n_boot: int=1):

    # alphas = np.append(np.logspace(.1, 1.5, num=25), [250])
    alphas = np.logspace(.1, 1.5, num=25)
    kwrgs_model = {'scoring':'neg_mean_absolute_error',
                   'alphas':alphas} # large a, strong regul.

    if target_ts is None:
        fc_mask = df_data.iloc[:,-1].loc[0]#.shift(lag, fill_value=False)
        target_ts = df_data.iloc[:,[0]].loc[0][fc_mask]

    else:
        target_ts = target_ts
    target_ts = (target_ts - target_ts.mean()) / target_ts.std()
    out = rg.fit_df_data_ridge(df_data=df_data,
                               target=target_ts,
                               keys=keys,
                               tau_min=min(lags), tau_max=max(lags),
                               kwrgs_model=kwrgs_model,
                               match_lag_region_to_lag_fc=match_lag,
                               transformer=fc_utils.standardize_on_train)

    prediction, weights, models_lags = out
    # get skill scores
    clim_mean_temp = float(target_ts.mean())
    RMSE_SS = fc_utils.ErrorSkillScore(constant_bench=clim_mean_temp).RMSE
    MAE_SS = fc_utils.ErrorSkillScore(constant_bench=clim_mean_temp).MAE
    score_func_list = [RMSE_SS, fc_utils.corrcoef, MAE_SS]

    df_train_m, df_test_s_m, df_test_m, df_boot = fc_utils.get_scores(prediction,
                                                             df_data.iloc[:,-2:],
                                                             score_func_list,
                                                             n_boot = n_boot,
                                                             blocksize=blocksize,
                                                             rng_seed=1)
    index = np.unique(core_pp.flatten([k.split('_') for k in  keys]))
    AR = [l for l in index if '..' not in l]
    AR = [l for l in AR if 'PDO' not in l]
    index = [k for k in index if k not in AR]
    df_test_m.index = ['AR' + ''.join(AR) +'_'+'_'.join(index)]
    n_splits = df_data.index.levels[0].size # test for high alpha
    for col in df_test_m.columns.levels[0]:
        cvfitalpha = [models_lags[f'lag_{col}'][f'split_{s}'].alpha_ for s in range(n_splits)]
        print('lag {} mean alpha {:.0f}'.format(col, np.mean(cvfitalpha)))
        maxalpha_c = list(cvfitalpha).count(alphas[-1])
        if maxalpha_c > n_splits/3:
            print(f'\nlag {col} alpha {int(np.mean(cvfitalpha))}')
            print(f'{maxalpha_c} splits are max alpha\n')
            # maximum regularization selected. No information in timeseries
            # df_test_m.loc[:,pd.IndexSlice[col, 'corrcoef']][:] = 0
            # df_boot.loc[:,pd.IndexSlice[col, 'corrcoef']][:] = 0
            no_info_fc.append(col)
    df_test = functions_pp.get_df_test(prediction.merge(df_data.iloc[:,-2:],
                                                    left_index=True,
                                                    right_index=True)).iloc[:,:-2]
    return prediction, df_test, df_test_m, df_boot, models_lags, weights, df_test_s_m, df_train_m

#%%

rg.get_ts_prec()

#%%
# =============================================================================
# forecasting RGDR (different lags)
# =============================================================================
no_info_fc = []
blocksize=1

region_labels = [1, 2]
rename_labels_d = {'1..1..sst': 'mid-Pacific (label 1)',
                   '1..2..sst': 'east-Pacific (label 2)'} # for plot only
y_keys = [k for k in rg.df_data.columns[:-2] if k not in df_PDO.columns]
y_keys = [k for k in y_keys if k not in [rg.TV.name]] # also remove LFV from target?
keys = [k for k in y_keys if int(k.split('..')[1]) in region_labels]

# =============================================================================
# Predictions
# =============================================================================
# out_regr2PDO = prediction_wrapper(df_data_r2PDO.copy(), keys=keys,
#                                  match_lag=match_lag, n_boot=n_boot)
dates = core_pp.get_subdates(rg.dates_TV, start_end_year=(1980,2020))
target_ts_temp = rg.TV.RV_ts.loc[dates]
clim_mean_temp = float(target_ts_temp.mean())
RMSE_SS = fc_utils.ErrorSkillScore(constant_bench=clim_mean_temp).RMSE
MAE_SS = fc_utils.ErrorSkillScore(constant_bench=clim_mean_temp).MAE
score_func_list = [RMSE_SS, fc_utils.corrcoef, MAE_SS, fc_utils.metrics.mean_absolute_error]
# predictions temp using SST regions
df_prec = merge_lagged_wrapper(rg.df_data.copy() , [1,2,3], keys)
df_prec = df_prec.loc[pd.IndexSlice[:, dates], :]
df_prec = df_prec.merge(rg.df_splits.loc[pd.IndexSlice[:, dates], :], left_index=True, right_index=True)

keys1 = core_pp.flatten([[k+f'_{l}' for l in [1] for k in keys]])
SST1 = prediction_wrapper(df_prec, lags=np.array([0]),
                          target_ts=target_ts_temp,
                          keys=keys1,
                          match_lag=False, n_boot=n_boot)

keys2 = core_pp.flatten([[k+f'_{l}' for l in [1,2] for k in keys]])
SST2 = prediction_wrapper(df_prec, lags=np.array([0]),
                          target_ts=target_ts_temp,
                          keys=keys2,
                          match_lag=False, n_boot=n_boot)

keys3 = core_pp.flatten([[k+f'_{l}' for l in [1,2,3] for k in keys]])
SST3 = prediction_wrapper(df_prec, lags=np.array([0]),
                          target_ts=target_ts_temp,
                          keys=keys3,
                          match_lag=False, n_boot=n_boot)

#%% For Marina Friedrich
# dates = core_pp.get_subdates(rg.dates_TV, start_end_year=(1980,2020))
# target_ts_temp = rg.TV.RV_ts.loc[dates]
# raw_target = rg.df_fulltso[['raw_target']].loc[dates]
# prec1 = functions_pp.get_df_test(df_prec)[['1..1..sst_1', '1..2..sst_1']]
# _merge = pd.concat([raw_target, target_ts_temp, prec1], axis=1)
# _merge = _merge.rename({'raw_target':'raw_target_cl4', 'RV4ts':'target_cl4', '1..1..sst_1':'sst_lag1_label1', '1..2..sst_1':'sst_lag1_label2'}, axis=1)
#%%
# =============================================================================
# #%% forecasting PDO (different lags)
# =============================================================================
rg.df_data = rg.merge_df_on_df_data(df_PDO)
keys = ['PDO']
blocksize=1
dates = core_pp.get_subdates(rg.dates_TV, start_end_year=(1980,2020))
target_ts_temp = rg.TV.RV_ts.loc[dates]
clim_mean_temp = float(target_ts_temp.mean())
RMSE_SS = fc_utils.ErrorSkillScore(constant_bench=clim_mean_temp).RMSE
MAE_SS = fc_utils.ErrorSkillScore(constant_bench=clim_mean_temp).MAE
score_func_list = [RMSE_SS, fc_utils.corrcoef, MAE_SS, fc_utils.metrics.mean_absolute_error]
# predictions temp using SST regions
df_prec = merge_lagged_wrapper(rg.df_data.copy() , [1,2,3], keys)
df_prec = df_prec.loc[pd.IndexSlice[:, dates], :]
df_prec = df_prec.merge(rg.df_splits.loc[pd.IndexSlice[:, dates], :], left_index=True, right_index=True)

keys1 = core_pp.flatten([[k+f'_{l}' for l in [1] for k in keys]])
PDO1 = prediction_wrapper(df_prec, lags=np.array([0]),
                          target_ts=target_ts_temp,
                          keys=keys1,
                          match_lag=False, n_boot=n_boot)

keys2 = core_pp.flatten([[k+f'_{l}' for l in [1,2] for k in keys]])
PDO2 = prediction_wrapper(df_prec, lags=np.array([0]),
                          target_ts=target_ts_temp,
                          keys=keys2,
                          match_lag=False, n_boot=n_boot)

keys3 = core_pp.flatten([[k+f'_{l}' for l in [1,2,3] for k in keys]])
PDO3 = prediction_wrapper(df_prec, lags=np.array([0]),
                          target_ts=target_ts_temp,
                          keys=keys3,
                          match_lag=False, n_boot=n_boot)


df_sum = pd.concat([SST1[2], SST2[2], SST3[2],
                    PDO1[2], PDO2[2], PDO3[2]])[0]

rename_m = {'corrcoef': 'Corr. coeff.', 'RMSE':'RMSE-SS',
            'MAE':'MAE-SS', 'CRPSS':'CRPSS'}
df_sum = df_sum.rename(rename_m, axis=1)

csv_filename = os.path.join(rg.path_outsub1, 'AR_models.csv')
df_sum.to_csv(csv_filename)



#%%
